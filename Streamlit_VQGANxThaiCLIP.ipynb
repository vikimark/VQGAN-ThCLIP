{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v03M2LxvYyAY"
      },
      "source": [
        "# ThaiCLIP guided VQGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup, import and define stuffs"
      ],
      "metadata": {
        "id": "CrcvJnuhd3R1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4xHSZ8auoDv"
      },
      "outputs": [],
      "source": [
        "#@title Setup and Imports (run this first)\n",
        "\n",
        "print(\"Downloading CLIP and installing requirements\")\n",
        "!git clone https://github.com/openai/CLIP                 &> /dev/null\n",
        "!pip install -q  ftfy regex tqdm omegaconf pytorch-lightning &> /dev/null\n",
        "\n",
        "# Downloading the pre-trained VQGAN model weights:\n",
        "print('Downloading ImageNet 16384 checkpoints')\n",
        "!curl -L 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1' > vqgan_imagenet_f16_16384.yaml\n",
        "!curl -L 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1' > vqgan_imagenet_f16_16384.ckpt\n",
        "\n",
        "print('Installing a few libraries')\n",
        "!git clone https://github.com/CompVis/taming-transformers &> /dev/null\n",
        "!pip install einops                                       &> /dev/null\n",
        "\n",
        "!git clone https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased\n",
        "!git clone https://github.com/vistec-AI/thai2transformers\n",
        "!git clone https://huggingface.co/vikimark/CLIP-MSE-WangchanBerta\n",
        "\n",
        "%cd /content/wangchanberta-base-att-spm-uncased/\n",
        "!git lfs pull\n",
        "%cd /content/CLIP-MSE-WangchanBerta\n",
        "!git lfs pull\n",
        "%cd /content\n",
        "!cp /content/thai2transformers/thai2transformers/preprocess.py /content\n",
        "!cp /content/CLIP-MSE-WangchanBerta/app.py /content\n",
        "\n",
        "!pip install timm\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install pythainlp\n",
        "!pip install pythainlp[translate]\n",
        "!pip install emoji\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "aCqyz6aaPGES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir steps"
      ],
      "metadata": {
        "id": "fcLjqxeSS1yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "7irAehwpP0Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VpZrCAGLTbhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Streamlit-VQGANxThaiCLIP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}