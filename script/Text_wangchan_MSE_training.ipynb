{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_wangchan_MSE_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## import && install packages"
      ],
      "metadata": {
        "id": "zBgiswBPMnq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/airesearch/wangchanberta-base-att-spm-uncased\n",
        "!git clone https://github.com/vistec-AI/thai2transformers\n",
        "\n",
        "%cd /content/wangchanberta-base-att-spm-uncased/\n",
        "!git lfs pull\n",
        "%cd /content\n",
        "!cp /content/thai2transformers/thai2transformers/preprocess.py /content\n",
        "\n",
        "!pip install timm\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install pythainlp\n",
        "!pip install pythainlp[translate]\n",
        "!pip install emoji"
      ],
      "metadata": {
        "id": "5kfaJl4mNbix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from tqdm.autonotebook import tqdm\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from transformers import (\n",
        "    CamembertModel,\n",
        "    CamembertTokenizer,\n",
        "    CamembertConfig,\n",
        ")\n",
        "from preprocess import process_transformers\n",
        "from pythainlp.translate import Translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICbHtR9MN3hP",
        "outputId": "c3d6ef80-541c-4480-fe1c-deb0ae406d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "HO_dxxMjOaM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # captions_path = captions_path\n",
        "    batch_size = 32\n",
        "    num_workers = 2\n",
        "    head_lr = 1e-3\n",
        "    text_encoder_lr = 1e-5\n",
        "    weight_decay = 1e-3\n",
        "    patience = 1\n",
        "    factor = 0.8\n",
        "    epochs = 100\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    text_encoder_model = \"/content/wangchanberta-base-att-spm-uncased\"\n",
        "    text_embedding = 768\n",
        "    text_tokenizer = \"/content/wangchanberta-base-att-spm-uncased\"\n",
        "    max_length = 200\n",
        "\n",
        "    pretrained = True\n",
        "    trainable = True\n",
        "    temperature = 1.0\n",
        "\n",
        "    # for projection head; used for both image and text encoders\n",
        "    num_projection_layers = 1\n",
        "    projection_dim = 512 \n",
        "    dropout = 0.1"
      ],
      "metadata": {
        "id": "gAMErZqFOb8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the network"
      ],
      "metadata": {
        "id": "MMg3bFMPMrGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, model_name=CFG.text_encoder_model, pretrained=CFG.pretrained, trainable=CFG.trainable):\n",
        "        super().__init__()\n",
        "        if pretrained:\n",
        "            self.model = CamembertModel.from_pretrained(model_name)\n",
        "        else:\n",
        "            self.model = CamembertModel(config=CamembertConfig())\n",
        "            \n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = trainable\n",
        "\n",
        "        # we are using the CLS token hidden representation as the sentence's embedding\n",
        "        self.target_token_idx = 0\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "        return last_hidden_state[:, self.target_token_idx, :]"
      ],
      "metadata": {
        "id": "NZjEc0k6OUIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim,\n",
        "        projection_dim=CFG.projection_dim,\n",
        "        dropout=CFG.dropout\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        projected = self.projection(x)\n",
        "        x = self.gelu(projected)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + projected\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3OhI9PkhO_F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        text_embedding = CFG.text_embedding\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.text_encoder = TextEncoder()\n",
        "        self.text_projection = ProjectionHead(embedding_dim=text_embedding)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # Getting Text Features\n",
        "        text_features = self.text_encoder(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"]\n",
        "        )\n",
        "        # Project to the same dim of image encoder\n",
        "        text_embeddings = self.text_projection(text_features)\n",
        "\n",
        "        return text_embeddings"
      ],
      "metadata": {
        "id": "JmXTHk4KPAGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define datasets loader && df maker"
      ],
      "metadata": {
        "id": "7Xm2KfrAOz5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_valid_dfs(df):\n",
        "    max_id = len(df)\n",
        "    text_ids = np.arange(0, max_id)\n",
        "    np.random.seed(42)\n",
        "    valid_ids = np.random.choice(\n",
        "        text_ids,\n",
        "        size=int(0.2 * len(text_ids)), replace=False\n",
        "    )\n",
        "    train_ids = [id_ for id_ in text_ids if id_ not in valid_ids]\n",
        "    train_dataframe = df[df.index.isin(train_ids)].reset_index(drop=True)\n",
        "    valid_dataframe = df[df.index.isin(valid_ids)].reset_index(drop=True)\n",
        "    return train_dataframe, valid_dataframe"
      ],
      "metadata": {
        "id": "q4-jyMNWWmXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, inputs, embed_text, tokenizer):\n",
        "\n",
        "        # self.ids = inputs['input_ids']\n",
        "        # self.attn = inputs['attention_mask']\n",
        "        self.captions = list(inputs['caption'])\n",
        "        self.index = list(inputs['index'])\n",
        "        self.encoded_captions = tokenizer(\n",
        "            list(self.captions), padding=True, truncation=True, max_length=CFG.max_length\n",
        "        )\n",
        "        self.target_embedding = embed_text\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "          batch= {\n",
        "            key: torch.tensor(values[idx])\n",
        "            for key, values in self.encoded_captions.items()\n",
        "          }\n",
        "          # batch[\"input_ids\"] = torch.tensor(self.ids[idx])\n",
        "          # batch[\"attention_mask\"] = torch.tensor(self.attn[idx])\n",
        "          batch[\"target\"] = torch.tensor(self.target_embedding[self.index[idx]])\n",
        "          return batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "def build_loaders(dataframe, text_embed, tokenizer, mode):\n",
        "    dataset = customImageDataset(dataframe, text_embed, tokenizer)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=CFG.batch_size,\n",
        "        num_workers=CFG.num_workers,\n",
        "        shuffle=True if mode == \"train\" else False,\n",
        "    )\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "aEKeDt3uOxw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "Zr_1kCebMvsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "YgcdvZ6qUzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training section"
      ],
      "metadata": {
        "id": "ahXZuqbwVA7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## dont forget to delete this sect\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open('/content/drive/MyDrive/ccs_synthetic_sub/openai_text_embedding_01.pickle', 'rb') as f:\n",
        "    text_embed = pickle.load(f)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/ccs_synthetic_sub/Thai_translated/thai_translated_01.csv')\n",
        "sr = pd.Series(list(range(1000000)), dtype=\"int32\", name = \"index\")\n",
        "df = df.join(sr)\n",
        "df"
      ],
      "metadata": {
        "id": "TBZqQzxLIY_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d0ab0c09-5061-4745-a755-68b18f595068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  caption   index\n",
              "0                      เก้าอี้ว่างที่นั่งอยู่หน้าหน้าต่าง       0\n",
              "1                 บ้านภายใต้การก่อสร้างที่มีการสร้างอาคาร       1\n",
              "2                             เด็กน้อยที่นั่งอยู่ในตะกร้า       2\n",
              "3                      ชายในผ้ากันเปื้อน<_>ทํางานในลังปลา       3\n",
              "4                  วิวจากสะพานเหนือแม่น้ําในเซ็นทรัลปาร์ค       4\n",
              "...                                                   ...     ...\n",
              "999995                         ผู้เล่นฟุตบอล<_>ได้แข่งกัน  999995\n",
              "999996  คอลเลกชันของมือวาดภาพการผจญภัยทะเลบนกระดานดําภ...  999996\n",
              "999997  คนที่สวมชุดที่มีสายกีต้าร์และยืนขึ้นโดยมีคนไมโ...  999997\n",
              "999998  แผนภาพสีขาวและสีเขียวของวงจรที่มีการคลิกเมาส์บ...  999998\n",
              "999999  ชายคนหนึ่งแถวเรือแคนูของเขาในทะเลสาบที่เงียบสง...  999999\n",
              "\n",
              "[1000000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b69b6af-c3db-4412-b620-dc0a721a5405\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>เก้าอี้ว่างที่นั่งอยู่หน้าหน้าต่าง</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>บ้านภายใต้การก่อสร้างที่มีการสร้างอาคาร</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>เด็กน้อยที่นั่งอยู่ในตะกร้า</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ชายในผ้ากันเปื้อน&lt;_&gt;ทํางานในลังปลา</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>วิวจากสะพานเหนือแม่น้ําในเซ็นทรัลปาร์ค</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>ผู้เล่นฟุตบอล&lt;_&gt;ได้แข่งกัน</td>\n",
              "      <td>999995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>คอลเลกชันของมือวาดภาพการผจญภัยทะเลบนกระดานดําภ...</td>\n",
              "      <td>999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>คนที่สวมชุดที่มีสายกีต้าร์และยืนขึ้นโดยมีคนไมโ...</td>\n",
              "      <td>999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>แผนภาพสีขาวและสีเขียวของวงจรที่มีการคลิกเมาส์บ...</td>\n",
              "      <td>999998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>ชายคนหนึ่งแถวเรือแคนูของเขาในทะเลสาบที่เงียบสง...</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b69b6af-c3db-4412-b620-dc0a721a5405')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b69b6af-c3db-4412-b620-dc0a721a5405 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b69b6af-c3db-4412-b620-dc0a721a5405');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group[\"lr\"]"
      ],
      "metadata": {
        "id": "yva4P4_JVPwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- tqdm track loss : finish\n",
        "- finish valid test : finish\n",
        "- lr_scheduler : ?\n",
        "- batch synchronize : finish\n",
        "- df match dataloader : untest\n",
        "\"\"\"\n",
        "\n",
        "def main(df):\n",
        "    train_df, valid_df = make_train_valid_dfs(df)\n",
        "    tokenizer = CamembertTokenizer.from_pretrained(CFG.text_tokenizer)\n",
        "    train_loader = build_loaders(train_df, text_embed, tokenizer, mode=\"train\")\n",
        "    valid_loader = build_loaders(valid_df, text_embed, tokenizer, mode=\"valid\")\n",
        "\n",
        "    model = TextModel().to(CFG.device)\n",
        "    params = [\n",
        "        {\"params\": model.text_encoder.parameters(), \n",
        "         \"lr\": CFG.text_encoder_lr},\n",
        "        {\"params\": model.text_projection.parameters(), \n",
        "         \"lr\": CFG.head_lr, \"weight_decay\": CFG.weight_decay}\n",
        "    ]\n",
        "    optimizer = torch.optim.AdamW(params, weight_decay=0.)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", patience=CFG.patience, factor=CFG.factor\n",
        "    )\n",
        "    \n",
        "    step = \"epoch\"\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "        model.train()\n",
        "        tqdm_object = tqdm(train_loader, total=len(train_loader))\n",
        "        for batch in tqdm_object:\n",
        "            batch = {k: v.to(CFG.device) for k, v in batch.items()}\n",
        "            y_pred = model(batch)\n",
        "            loss = criterion(y_pred, batch[\"target\"].squeeze(1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if step == 'batch':\n",
        "                lr_scheduler.step()\n",
        "\n",
        "            # count = batch['target'].size(0)\n",
        "            \n",
        "            tqdm_object.set_postfix(train_loss=loss, lr=get_lr(optimizer))\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            tqdm_object = tqdm(valid_loader, total=len(valid_loader))\n",
        "            for batch in tqdm_object:\n",
        "                batch = {k: torch.tensor(v).to(CFG.device) for k, v in batch.items()}\n",
        "                y_pred = model(batch)\n",
        "                valid_loss = criterion(y_pred, batch[\"target\"].squeeze(1))\n",
        "\n",
        "                # count = batch['target'].size(0)\n",
        "\n",
        "                tqdm_object.set_postfix(valid_loss = valid_loss)\n",
        "\n",
        "                if valid_loss < best_loss:\n",
        "                    best_loss = valid_loss\n",
        "                    torch.save(model.state_dict(), \"text_MSE.pt\")\n",
        "                    print(\"Saved Best Model!\")\n",
        "\n",
        "                lr_scheduler.step(valid_loss)\n",
        "\n",
        "            torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "zTcEpm0qMu_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(df)"
      ],
      "metadata": {
        "id": "_WbPRKoIIRS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ub0AImjNISl7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}